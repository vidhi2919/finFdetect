# # main.py
# """
# FastAPI backend for Fraud Investigator MVP
# ==========================================

# Goal:
# - Replace Streamlit dashboard with deployable REST API.
# - Endpoints are separable (loosely coupled), easy to deploy.
# - Reads precomputed JSON artifacts from ./outputs (generated by your agents).

# Artifacts expected (in outputs/):
# - final_case_reports.json          (list of case reports)
# - final_risk_scores.json           (list OR dict; handled)
# - pattern_detections_langgraph.json (list of detections)
# - timeline_reconstruction.json     (dict; optional)
# - correlation.json                 (dict; optional)
# - transaction_analysis.json        (dict; optional)
# - rag_reports.json                 (list; optional)
# - graph_viz/*.png                  (optional)

# Run:
#   uvicorn main:app --reload

# Deploy:
#   uvicorn main:app --host 0.0.0.0 --port 8000
# """

# from __future__ import annotations

# import json
# import os
# from pathlib import Path
# from typing import Any, Dict, List, Optional, Tuple

# from fastapi import FastAPI, HTTPException, Query
# from fastapi.middleware.cors import CORSMiddleware
# from fastapi.responses import FileResponse, JSONResponse
# from pydantic import BaseModel


# # -----------------------------
# # Config
# # -----------------------------
# OUTPUT_DIR = Path(os.getenv("OUTPUT_DIR", "outputs"))
# DEFAULT_TOP_N = int(os.getenv("DEFAULT_TOP_N", "50"))

# FILES = {
#     "case_reports": OUTPUT_DIR / "final_case_reports.json",
#     "risk_scores": OUTPUT_DIR / "final_risk_scores.json",
#     "patterns": OUTPUT_DIR / "pattern_detections_langgraph.json",
#     "timeline": OUTPUT_DIR / "timeline_reconstruction.json",
#     "correlation": OUTPUT_DIR / "correlation.json",
#     "txn_analysis": OUTPUT_DIR / "transaction_analysis.json",
#     "rag_reports": OUTPUT_DIR / "rag_reports.json",
# }

# GRAPH_VIZ_DIR = OUTPUT_DIR / "graph_viz"


# # -----------------------------
# # App
# # -----------------------------
# app = FastAPI(
#     title="Fraud Investigator API (MVP)",
#     version="1.0.0",
#     description="Deterministic fraud analytics backend: alerts, case reports, graph images, and RAG explanations.",
# )

# # Allow frontend deployments (optional). Restrict in production.
# app.add_middleware(
#     CORSMiddleware,
#     allow_origins=["*"],
#     allow_credentials=False,
#     allow_methods=["*"],
#     allow_headers=["*"],
# )


# # -----------------------------
# # Models (minimal, flexible)
# # -----------------------------
# class HealthResponse(BaseModel):
#     status: str
#     outputs_dir: str
#     available_artifacts: Dict[str, bool]


# class AlertRow(BaseModel):
#     account_id: str
#     risk_score: float
#     risk_band: str
#     patterns: List[str]


# class AlertsResponse(BaseModel):
#     total: int
#     returned: int
#     items: List[AlertRow]


# class CaseReportResponse(BaseModel):
#     report: Dict[str, Any]


# class PatternsResponse(BaseModel):
#     total: int
#     returned: int
#     items: List[Dict[str, Any]]


# class RagResponse(BaseModel):
#     total: int
#     returned: int
#     items: List[Dict[str, Any]]


# # -----------------------------
# # Helpers
# # -----------------------------
# def _read_json(path: Path) -> Any:
#     if not path.exists():
#         raise FileNotFoundError(str(path))
#     return json.loads(path.read_text())


# def _safe_read_json(path: Path) -> Optional[Any]:
#     try:
#         return _read_json(path)
#     except FileNotFoundError:
#         return None


# def _risk_band(score_0_100: float) -> str:
#     if score_0_100 >= 70:
#         return "HIGH"
#     if score_0_100 >= 40:
#         return "MEDIUM"
#     return "LOW"


# def _normalize_risk_scores(risk_obj: Any) -> List[Dict[str, Any]]:
#     """
#     Accepts:
#     - list: [{"account_id", "risk_score", "risk_band", "components"...}, ...]
#     - dict: { "risk_score": [...] } (legacy)
#     - dict: { "ACC0001": {...} } (legacy)
#     Returns list of dict rows with account_id + risk_score + risk_band + components
#     """
#     if risk_obj is None:
#         return []

#     if isinstance(risk_obj, list):
#         rows = risk_obj
#     elif isinstance(risk_obj, dict) and "risk_score" in risk_obj and isinstance(risk_obj["risk_score"], list):
#         rows = risk_obj["risk_score"]
#     elif isinstance(risk_obj, dict):
#         rows = []
#         for acc, data in risk_obj.items():
#             if isinstance(data, dict):
#                 rows.append({"account_id": acc, **data})
#             else:
#                 rows.append({"account_id": acc, "risk_score": float(data)})
#     else:
#         return []

#     # Normalize keys
#     norm = []
#     for r in rows:
#         acc = r.get("account_id")
#         if not acc:
#             continue
#         score = r.get("risk_score", r.get("final_risk", r.get("final_score", 0.0)))
#         try:
#             score_f = float(score)
#         except Exception:
#             score_f = 0.0
#         band = r.get("risk_band") or _risk_band(score_f)
#         norm.append({**r, "account_id": acc, "risk_score": score_f, "risk_band": band})
#     return norm


# def _load_case_reports() -> List[Dict[str, Any]]:
#     data = _read_json(FILES["case_reports"])
#     if not isinstance(data, list):
#         raise ValueError("final_case_reports.json must be a list")
#     return data


# def _find_case_report(reports: List[Dict[str, Any]], account_id: str) -> Optional[Dict[str, Any]]:
#     for r in reports:
#         if r.get("account_id") == account_id:
#             return r
#     return None


# def _extract_patterns_from_report(report: Dict[str, Any]) -> List[str]:
#     pats = []
#     for p in report.get("patterns_detected", []) or []:
#         if not isinstance(p, dict):
#             continue
#         pats.append(p.get("pattern_type") or p.get("pattern") or "")
#     return sorted([x for x in set(pats) if x])


# # -----------------------------
# # Core endpoints (separable)
# # -----------------------------
# @app.get("/health", response_model=HealthResponse)
# def health():
#     return {
#         "status": "ok",
#         "outputs_dir": str(OUTPUT_DIR),
#         "available_artifacts": {k: v.exists() for k, v in FILES.items()},
#     }


# @app.get("/alerts", response_model=AlertsResponse)
# def get_alerts(
#     top_n: int = Query(DEFAULT_TOP_N, ge=1, le=1000),
#     band: Optional[str] = Query(None, description="Filter by risk band: HIGH | MEDIUM | LOW"),
# ):
#     """
#     Returns ranked alerts derived from final_case_reports.json (preferred),
#     falling back to final_risk_scores.json if needed.

#     Does NOT depend on other endpoints.
#     """
#     reports = _safe_read_json(FILES["case_reports"])
#     if isinstance(reports, list) and reports:
#         # Build alert rows from case reports (best)
#         rows: List[AlertRow] = []
#         for r in reports:
#             risk = r.get("risk", {}) or {}
#             score = float(risk.get("final_score", 0.0))
#             rb = risk.get("band") or _risk_band(score)
#             if band and rb != band:
#                 continue
#             rows.append(
#                 AlertRow(
#                     account_id=r.get("account_id", ""),
#                     risk_score=score,
#                     risk_band=rb,
#                     patterns=_extract_patterns_from_report(r),
#                 )
#             )
#         rows = sorted(rows, key=lambda x: x.risk_score, reverse=True)[:top_n]
#         return {"total": len(rows), "returned": len(rows), "items": rows}

#     # Fallback: risk scores only
#     risk_obj = _safe_read_json(FILES["risk_scores"])
#     risk_rows = _normalize_risk_scores(risk_obj)
#     if band:
#         risk_rows = [r for r in risk_rows if (r.get("risk_band") == band)]
#     risk_rows = sorted(risk_rows, key=lambda r: r.get("risk_score", 0.0), reverse=True)[:top_n]

#     items = [
#         AlertRow(
#             account_id=r["account_id"],
#             risk_score=float(r.get("risk_score", 0.0)),
#             risk_band=r.get("risk_band") or _risk_band(float(r.get("risk_score", 0.0))),
#             patterns=[],
#         )
#         for r in risk_rows
#     ]
#     return {"total": len(items), "returned": len(items), "items": items}


# @app.get("/cases/{account_id}", response_model=CaseReportResponse)
# def get_case_report(account_id: str):
#     """
#     Returns the full case report for one account.
#     Independent: reads final_case_reports.json directly.
#     """
#     try:
#         reports = _load_case_reports()
#     except FileNotFoundError:
#         raise HTTPException(status_code=404, detail="final_case_reports.json not found in outputs/")
#     except Exception as e:
#         raise HTTPException(status_code=500, detail=f"Failed to load case reports: {e}")

#     report = _find_case_report(reports, account_id)
#     if not report:
#         raise HTTPException(status_code=404, detail=f"No case report found for {account_id}")

#     return {"report": report}


# @app.get("/cases/{account_id}/graph-image")
# def get_case_graph_image(account_id: str):
#     """
#     Serves pre-rendered graph PNG (NetworkX/Matplotlib output).
#     Independent: only needs outputs/graph_viz/{account_id}.png
#     """
#     img = GRAPH_VIZ_DIR / f"{account_id}.png"
#     if not img.exists():
#         raise HTTPException(status_code=404, detail=f"Graph image not found: {img}")
#     return FileResponse(str(img), media_type="image/png", filename=img.name)


# @app.get("/patterns", response_model=PatternsResponse)
# def list_patterns(
#     account_id: Optional[str] = Query(None),
#     top_n: int = Query(200, ge=1, le=5000),
# ):
#     """
#     Lists raw pattern detections from pattern_detections_langgraph.json.
#     Independent from alerts/cases.
#     """
#     data = _safe_read_json(FILES["patterns"])
#     if data is None:
#         raise HTTPException(status_code=404, detail="pattern_detections_langgraph.json not found")

#     if not isinstance(data, list):
#         raise HTTPException(status_code=500, detail="patterns file must be a list")

#     items = data
#     if account_id:
#         items = [d for d in items if (d.get("account_id") == account_id) or (d.get("detection", {}).get("account_id") == account_id)]

#     return {"total": len(items), "returned": min(len(items), top_n), "items": items[:top_n]}


# @app.get("/rag", response_model=RagResponse)
# def list_rag_reports(
#     account_id: Optional[str] = Query(None),
#     top_n: int = Query(200, ge=1, le=5000),
# ):
#     """
#     Lists RAG reasoning outputs from rag_reports.json.
#     Independent from other endpoints.
#     """
#     data = _safe_read_json(FILES["rag_reports"])
#     if data is None:
#         raise HTTPException(status_code=404, detail="rag_reports.json not found")

#     if not isinstance(data, list):
#         raise HTTPException(status_code=500, detail="rag_reports.json must be a list")

#     items = data
#     if account_id:
#         items = [r for r in items if r.get("account_id") == account_id]

#     return {"total": len(items), "returned": min(len(items), top_n), "items": items[:top_n]}


# @app.get("/artifacts")
# def list_artifacts():
#     """
#     Quick visibility into what artifacts exist and their sizes.
#     Independent helper endpoint for deployment debugging.
#     """
#     out = {}
#     for name, path in FILES.items():
#         out[name] = {
#             "path": str(path),
#             "exists": path.exists(),
#             "bytes": path.stat().st_size if path.exists() else None,
#         }

#     out["graph_viz_dir"] = {
#         "path": str(GRAPH_VIZ_DIR),
#         "exists": GRAPH_VIZ_DIR.exists(),
#         "png_count": len(list(GRAPH_VIZ_DIR.glob("*.png"))) if GRAPH_VIZ_DIR.exists() else 0,
#     }
#     return JSONResponse(out)


# # -----------------------------
# # Optional: filtered ranked cases
# # -----------------------------
# @app.get("/cases", response_model=AlertsResponse)
# def list_cases_ranked(
#     top_n: int = Query(DEFAULT_TOP_N, ge=1, le=1000),
#     band: Optional[str] = Query(None),
#     include_patterns: bool = Query(True),
# ):
#     """
#     Ranked list of accounts derived from case reports (if available).
#     Similar to /alerts, but 'cases' semantics.
#     Still independent: reads final_case_reports.json directly.
#     """
#     reports = _safe_read_json(FILES["case_reports"])
#     if not isinstance(reports, list) or not reports:
#         raise HTTPException(status_code=404, detail="final_case_reports.json not found or empty")

#     items: List[AlertRow] = []
#     for r in reports:
#         risk = r.get("risk", {}) or {}
#         score = float(risk.get("final_score", 0.0))
#         rb = risk.get("band") or _risk_band(score)
#         if band and rb != band:
#             continue
#         items.append(
#             AlertRow(
#                 account_id=r.get("account_id", ""),
#                 risk_score=score,
#                 risk_band=rb,
#                 patterns=_extract_patterns_from_report(r) if include_patterns else [],
#             )
#         )

#     items = sorted(items, key=lambda x: x.risk_score, reverse=True)[:top_n]
#     return {"total": len(items), "returned": len(items), "items": items}





# main.py
"""
FastAPI backend for Fraud Investigator MVP
==========================================
"""

from __future__ import annotations

import json
import os
from io import BytesIO
from pathlib import Path
from typing import Any, Dict, List, Optional

from datetime import datetime
from fastapi import FastAPI, HTTPException, Query
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, JSONResponse
from pydantic import BaseModel

# PDF
from reportlab.lib.pagesizes import A4
from reportlab.lib.units import cm
from reportlab.lib import colors
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.platypus import (
    SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle,
    Image as RLImage, PageBreak
)

from datetime import datetime
from io import BytesIO
from fastapi.responses import StreamingResponse

from reportlab.lib.pagesizes import A4
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, Image
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib import colors
from reportlab.lib.units import inch

# -----------------------------
# Config
# -----------------------------
OUTPUT_DIR = Path(os.getenv("OUTPUT_DIR", "outputs"))
DEFAULT_TOP_N = int(os.getenv("DEFAULT_TOP_N", "50"))
PDF_DIR = OUTPUT_DIR / "pdf_reports"
PDF_DIR.mkdir(parents=True, exist_ok=True)

FILES = {
    "case_reports": OUTPUT_DIR / "final_case_reports.json",
    "risk_scores": OUTPUT_DIR / "final_risk_scores.json",
    "patterns": OUTPUT_DIR / "pattern_detections_langgraph.json",
    "rag_reports": OUTPUT_DIR / "rag_reports.json",
}

GRAPH_VIZ_DIR = OUTPUT_DIR / "graph_viz"

# -----------------------------
# App
# -----------------------------
app = FastAPI(
    title="Fraud Investigator API",
    version="1.1.0",
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=False,
    allow_methods=["*"],
    allow_headers=["*"],
)

# -----------------------------
# Models
# -----------------------------
class HealthResponse(BaseModel):
    status: str
    outputs_dir: str
    available_artifacts: Dict[str, bool]

class AlertRow(BaseModel):
    account_id: str
    risk_score: float
    risk_band: str
    patterns: List[str]

class AlertsResponse(BaseModel):
    total: int
    returned: int
    items: List[AlertRow]

class CaseReportResponse(BaseModel):
    report: Dict[str, Any]

class RagResponse(BaseModel):
    total: int
    returned: int
    items: List[Dict[str, Any]]

# -----------------------------
# Helpers
# -----------------------------
def _read_json(path: Path) -> Any:
    if not path.exists():
        raise FileNotFoundError(str(path))
    return json.loads(path.read_text())

def _safe_read_json(path: Path) -> Optional[Any]:
    try:
        return _read_json(path)
    except FileNotFoundError:
        return None

def _risk_band(score: float) -> str:
    if score >= 70:
        return "HIGH"
    if score >= 40:
        return "MEDIUM"
    return "LOW"

def _load_case_reports() -> List[Dict[str, Any]]:
    data = _read_json(FILES["case_reports"])
    if not isinstance(data, list):
        raise ValueError("final_case_reports.json must be a list")
    return data

def _find_case(reports, acc):
    return next((r for r in reports if r.get("account_id") == acc), None)

def _find_rag(items, acc):
    if not isinstance(items, list):
        return None
    return next((r for r in items if r.get("account_id") == acc), None)

def _fmt_inr(x):
    try:
        return f"₹{float(x):,.0f}"
    except Exception:
        return "—"
def _unique_pattern_names_from_case_report(case_report: Dict[str, Any]) -> List[str]:
    """
    Returns UNIQUE pattern names from case_report["patterns_detected"]
    Handles both:
      - {"pattern_type": "..."}
      - {"pattern": "..."}
      - nested detection dicts
    """
    raw = case_report.get("patterns_detected") or []
    names: List[str] = []

    for p in raw:
        if not isinstance(p, dict):
            continue

        # common fields
        name = p.get("pattern_type") or p.get("pattern")

        # sometimes pattern is nested
        if not name and isinstance(p.get("detection"), dict):
            det = p["detection"]
            name = det.get("pattern_type") or det.get("pattern")

        if isinstance(name, str) and name.strip():
            names.append(name.strip())

    # unique + stable order
    seen = set()
    out = []
    for n in names:
        key = n.lower()
        if key not in seen:
            seen.add(key)
            out.append(n)
    return out

def _load_rag_item_by_account(account_id: str) -> Optional[Dict[str, Any]]:
    data = _safe_read_json(FILES["rag_reports"])
    if not isinstance(data, list):
        return None
    for item in data:
        if item.get("account_id") == account_id:
            return item
    return None


# -----------------------------
# PDF Builder
# -----------------------------
def build_pdf(account_id: str, case: Dict[str, Any], rag: Optional[Dict[str, Any]]) -> bytes:
    buf = BytesIO()
    doc = SimpleDocTemplate(buf, pagesize=A4,
                            leftMargin=1.5*cm, rightMargin=1.5*cm,
                            topMargin=1.5*cm, bottomMargin=1.5*cm)

    styles = getSampleStyleSheet()
    title = ParagraphStyle("T", parent=styles["Title"], fontSize=18)
    h = ParagraphStyle("H", parent=styles["Heading2"], fontSize=12)
    b = ParagraphStyle("B", parent=styles["BodyText"], fontSize=9.5)

    story = []

    # Header
    story.append(Paragraph("Fraud Investigation Report", title))
    story.append(Paragraph(f"<b>Account:</b> {account_id}", b))
    story.append(Paragraph(f"<b>Generated:</b> {datetime.now()}", b))
    story.append(Spacer(1, 10))

    # Summary table
    risk = case.get("risk", {})
    ge = case.get("graph_evidence", {})
    rows = [
        ["Risk Score", risk.get("final_score"), "Risk Band", risk.get("band")],
        ["Total Sent", _fmt_inr(ge.get("total_flow", {}).get("sent")),
         "Total Received", _fmt_inr(ge.get("total_flow", {}).get("received"))],
        ["In Degree", ge.get("in_degree"), "Out Degree", ge.get("out_degree")],
        ["Transactions", ge.get("transaction_count"),
         "Counterparties", ge.get("unique_counterparties")],
    ]

    t = Table(rows, colWidths=[3.5*cm, 4.5*cm, 3.5*cm, 4.5*cm])
    t.setStyle(TableStyle([
        ("BOX", (0,0), (-1,-1), 0.5, colors.black),
        ("GRID", (0,0), (-1,-1), 0.25, colors.grey),
        ("BACKGROUND", (0,0), (-1,0), colors.whitesmoke),
    ]))

    story.append(Paragraph("Executive Summary", h))
    story.append(t)

    # # Patterns
    # story.append(Spacer(1, 10))
    # story.append(Paragraph("Detected Patterns", h))
    # pats = case.get("patterns_detected", [])
    # if pats:
    #     story.append(Paragraph("<br/>".join(
    #         f"• <b>{p.get('pattern_type')}</b> — {p.get('description','')}"
    #         for p in pats
    #     ), b))
    # else:
    #     story.append(Paragraph("—", b))

    pats = case.get("patterns_detected", []) or []

    # Deduplicate by pattern_type (stable order)
    unique_patterns = {}
    for p in pats:
        if not isinstance(p, dict):
            continue
        name = p.get("pattern_type") or p.get("pattern")
        if not name:
            continue

        key = name.strip().lower()
        if key not in unique_patterns:
            unique_patterns[key] = {
                "name": name.strip(),
                "description": p.get("description", "").strip()
            }
    story.append(Spacer(1, 10))
    story.append(Paragraph("Detected Patterns", h))

    if unique_patterns:
        story.append(
            Paragraph(
                "<br/>".join(
                    f"• <b>{v['name']}</b>"
                    + (f" — {v['description']}" if v["description"] else "")
                    for v in unique_patterns.values()
                ),
                b
            )
        )
    else:
        story.append(Paragraph("—", b))



    # Graph
    img = GRAPH_VIZ_DIR / f"{account_id}.png"
    if img.exists():
        story.append(Spacer(1, 10))
        story.append(Paragraph("Transaction Graph", h))
        story.append(RLImage(str(img), width=16*cm, height=10*cm))

    # RAG
    if rag:
        story.append(PageBreak())
        story.append(Paragraph("RAG Narrative & Investigator Checklist", h))
        story.append(Paragraph(rag.get("report", "—").replace("\n", "<br/>"), b))

    doc.build(story)
    return buf.getvalue()

# -----------------------------
# Endpoints
# -----------------------------
@app.get("/health", response_model=HealthResponse)
def health():
    return {
        "status": "ok",
        "outputs_dir": str(OUTPUT_DIR),
        "available_artifacts": {k: v.exists() for k, v in FILES.items()},
    }

@app.get("/cases/{account_id}", response_model=CaseReportResponse)
def get_case(account_id: str):
    reports = _load_case_reports()
    case = _find_case(reports, account_id)
    if not case:
        raise HTTPException(404, "Case not found")
    return {"report": case}

@app.get("/rag", response_model=RagResponse)
def get_rag(account_id: Optional[str] = None):
    items = _safe_read_json(FILES["rag_reports"]) or []
    if account_id:
        items = [r for r in items if r.get("account_id") == account_id]
    return {"total": len(items), "returned": len(items), "items": items}

@app.get("/reports/{account_id}/pdf")
def report_pdf(account_id: str):
    reports = _load_case_reports()
    case = _find_case(reports, account_id)
    if not case:
        raise HTTPException(404, "Case not found")

    rag_items = _safe_read_json(FILES["rag_reports"])
    rag = _find_rag(rag_items, account_id)

    pdf_bytes = build_pdf(account_id, case, rag)
    out = PDF_DIR / f"{account_id}.pdf"
    out.write_bytes(pdf_bytes)

    return FileResponse(out, media_type="application/pdf", filename=out.name)

@app.get("/reports/{account_id}/pdf")
def get_report_pdf(account_id: str):
    """
    Generates a pretty PDF report using:
    - final_case_reports.json (metrics + graph image + patterns)
    - rag_reports.json (detailed narrative under item["report"])
    """
    # 1) Load case report
    try:
        reports = _load_case_reports()
    except FileNotFoundError:
        raise HTTPException(status_code=404, detail="final_case_reports.json not found")
    case = _find_case_report(reports, account_id)
    if not case:
        raise HTTPException(status_code=404, detail=f"No case report found for {account_id}")

    # 2) Load RAG report (optional but preferred)
    rag_item = _load_rag_item_by_account(account_id)
    rag_text = (rag_item or {}).get("report") or "No RAG narrative available for this account."
    retrieval = (rag_item or {}).get("retrieval") or []

    # 3) Unique patterns
    unique_patterns = _unique_pattern_names_from_case_report(case)

    # 4) Build PDF
    buf = BytesIO()
    doc = SimpleDocTemplate(
        buf,
        pagesize=A4,
        leftMargin=36,
        rightMargin=36,
        topMargin=36,
        bottomMargin=36,
        title=f"Investigation Report - {account_id}",
    )

    styles = getSampleStyleSheet()
    styles.add(ParagraphStyle(name="H1", parent=styles["Heading1"], fontSize=16, spaceAfter=10))
    styles.add(ParagraphStyle(name="H2", parent=styles["Heading2"], fontSize=12, spaceAfter=8))
    styles.add(ParagraphStyle(name="Body", parent=styles["BodyText"], fontSize=10, leading=14))
    styles.add(ParagraphStyle(name="MonoSmall", parent=styles["BodyText"], fontSize=9, leading=12, fontName="Courier"))

    story = []

    # Header
    story.append(Paragraph(f"Fraud Investigation Report: <b>{account_id}</b>", styles["H1"]))
    story.append(Paragraph(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M')}", styles["Body"]))
    story.append(Spacer(1, 12))

    # Risk summary table
    risk = case.get("risk", {}) or {}
    risk_score = risk.get("final_score", "—")
    risk_band = risk.get("band", "—")

    ge = case.get("graph_evidence", {}) or {}
    total_flow = ge.get("total_flow", {}) or {}
    sent = total_flow.get("sent", "—")
    received = total_flow.get("received", "—")
    in_deg = ge.get("in_degree", "—")
    out_deg = ge.get("out_degree", "—")
    tx_count = ge.get("transaction_count", "—")
    uniq_cp = ge.get("unique_counterparties", "—")

    table_data = [
        ["Risk Score", str(risk_score), "Risk Band", str(risk_band)],
        ["Total Sent", str(sent), "Total Received", str(received)],
        ["In Degree", str(in_deg), "Out Degree", str(out_deg)],
        ["Transaction Count", str(tx_count), "Unique Counterparties", str(uniq_cp)],
    ]

    t = Table(table_data, colWidths=[1.4 * inch, 2.0 * inch, 1.6 * inch, 2.0 * inch])
    t.setStyle(
        TableStyle(
            [
                ("BACKGROUND", (0, 0), (-1, 0), colors.whitesmoke),
                ("GRID", (0, 0), (-1, -1), 0.5, colors.lightgrey),
                ("FONTNAME", (0, 0), (-1, -1), "Helvetica"),
                ("FONTSIZE", (0, 0), (-1, -1), 9),
                ("VALIGN", (0, 0), (-1, -1), "MIDDLE"),
                ("ROWBACKGROUNDS", (0, 0), (-1, -1), [colors.white, colors.HexColor("#FAFAFA")]),
            ]
        )
    )
    story.append(Paragraph("Risk & Transaction Summary", styles["H2"]))
    story.append(t)
    story.append(Spacer(1, 12))

    # Unique patterns
    story.append(Paragraph("Detected Patterns (Unique)", styles["H2"]))
    if unique_patterns:
        story.append(Paragraph(", ".join(unique_patterns), styles["Body"]))
    else:
        story.append(Paragraph("No patterns detected.", styles["Body"]))
    story.append(Spacer(1, 12))

    # Graph image if present
    img_path = (case.get("graph_evidence", {}) or {}).get("graph_visual_path")
    if img_path and Path(img_path).exists():
        story.append(Paragraph("Graph Evidence", styles["H2"]))
        story.append(Image(img_path, width=6.5 * inch, height=4.0 * inch))
        story.append(Spacer(1, 12))

    # ✅ RAG detailed narrative (this is your main request)
    story.append(Paragraph("Detailed Investigation Narrative (RAG)", styles["H2"]))
    for para in rag_text.split("\n"):
        para = para.strip()
        if not para:
            story.append(Spacer(1, 6))
            continue
        story.append(Paragraph(para.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;"), styles["Body"]))
    story.append(Spacer(1, 12))

    # Sources / retrieval evidence (top N)
    story.append(Paragraph("Supporting Sources (Top Retrieval)", styles["H2"]))
    if retrieval:
        for i, r in enumerate(retrieval[:6], start=1):
            score = r.get("score")
            meta = r.get("metadata", {}) or {}
            src = meta.get("source_path") or r.get("source") or "unknown"
            excerpt = (r.get("text") or "").strip()

            story.append(Paragraph(f"<b>[{i}]</b> score={score} — {src}", styles["MonoSmall"]))
            if excerpt:
                story.append(Paragraph(excerpt[:600].replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;"), styles["Body"]))
            story.append(Spacer(1, 8))
    else:
        story.append(Paragraph("No retrieval sources available.", styles["Body"]))

    doc.build(story)
    buf.seek(0)

    return StreamingResponse(
        buf,
        media_type="application/pdf",
        headers={"Content-Disposition": f'inline; filename="report_{account_id}.pdf"'},
    )
